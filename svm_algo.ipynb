{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm  \n",
    "from sklearn import metrics  \n",
    "import pandas as pd   \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8320, 20)\n",
      "(8320,)\n"
     ]
    }
   ],
   "source": [
    "x = np.loadtxt('z_runs.txt')\n",
    "y = np.loadtxt('ground_truth.txt')\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(x,y,ratio=0.7):\n",
    "    N,D = np.shape(x)\n",
    "    ind_cut = int(ratio * N)\n",
    "    ind = np.random.permutation(N)\n",
    "    train_data = x[ind[:ind_cut]]\n",
    "    val_data = x[ind[ind_cut:]]\n",
    "    train_label = y[ind[:ind_cut]]\n",
    "    val_label = y[ind[ind_cut:]]\n",
    "    return train_data, train_label, val_data, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, val_data, val_label = dataset_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Accuracy(y_true, y_pred): #Accuracy 准确率：分类器正确分类的样本数与总样本数之比 \n",
    "    accuracy = metrics.accuracy_score(y_true,y_pred)  \n",
    "    return accuracy\n",
    " \n",
    "def Get_Precision_score(y_true, y_pred): #Precision：精准率 正确被预测的正样本(TP)占所有被预测为正样本(TP+FP)的比例. \n",
    "    precision = metrics.precision_score(y_true,y_pred)  \n",
    "    return precision\n",
    " \n",
    "def Get_Recall(y_true, y_pred): #Recall 召回率 正确被预测的正样本(TP)占所有真正 正样本(TP+FN)的比例.  \n",
    "    Recall = metrics.recall_score(y_true,y_pred)  \n",
    "    return Recall \n",
    " \n",
    "def Get_f1_score(y_true, y_pred): #F1-score: 精确率(precision)和召回率(Recall)的调和平均数  \n",
    "    f1_score = metrics.f1_score(y_true,y_pred)  \n",
    "    return f1_score\n",
    " \n",
    "def Get_Auc_value(y_true,y_proba):  \n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(samples_test_y, proba_pred_y, pos_label=2)    \n",
    "    auc = metrics.roc_auc_score(y_true, y_proba)  \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16427826 0.83572174]\n",
      " [0.12831059 0.87168941]\n",
      " [0.13890595 0.86109405]\n",
      " ...\n",
      " [0.19590688 0.80409312]\n",
      " [0.43377627 0.56622373]\n",
      " [0.11345228 0.88654772]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_probability = clf.predict_proba(val_data)  \n",
    "print(y_pred_probability) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(y_pred_probability)  \n",
    "proba_pred_y = np.array(df2[1])  #截取样本点预测为正样本的预测概率\n",
    "# df2.to_csv(\"pred_probability.csv\")  \n",
    "# print(proba_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 模型打分: Score = 0.817708\n",
      "SVM Accuracy_Score = 0.817708\n",
      "SVM Precision = 0.749030\n",
      "SVM Recall = 0.998523\n",
      "SVM F1-Score  = 0.855967\n",
      "SVM AUC value: AUC = 0.866618\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(val_data,val_label)  \n",
    "print(\"SVM 模型打分: Score = %f\"%score)  \n",
    "accuracy = Get_Accuracy(val_label,y_predict)\n",
    "print(\"SVM Accuracy_Score = %f\"%accuracy)  \n",
    "precision = Get_Precision_score(val_label,y_predict)\n",
    "print(\"SVM Precision = %f\"%precision)\n",
    "recall = Get_Recall(val_label,y_predict)\n",
    "print(\"SVM Recall = %f\"%recall) \n",
    "f1_score = Get_f1_score(val_label,y_predict)\n",
    "print(\"SVM F1-Score  = %f\"%f1_score) \n",
    "auc = Get_Auc_value(val_label, proba_pred_y)\n",
    "print(\"SVM AUC value: AUC = %f\"%auc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import BasicAer\n",
    "from qiskit.aqua.utils import split_dataset_to_data_and_labels, map_label_to_class_name\n",
    "from qiskit.aqua.input import ClassificationInput\n",
    "from qiskit.aqua import run_algorithm, QuantumInstance\n",
    "from qiskit.aqua.algorithms import QSVM\n",
    "from qiskit.aqua.components.feature_maps import SecondOrderExpansion\n",
    "\n",
    "# setup aqua logging\n",
    "import logging\n",
    "from qiskit.aqua import set_qiskit_aqua_logging\n",
    "# set_qiskit_aqua_logging(logging.DEBUG)  # choose INFO, DEBUG to see the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_normal_abnormal(train_data,train_label):\n",
    "    N = len(train_data)\n",
    "    data_normal = []\n",
    "    data_abnormal = []\n",
    "    for k in range(N):\n",
    "        if train_label[k] == 1:\n",
    "            tmp = train_data[k]\n",
    "            data_normal.append(tmp)\n",
    "        elif train_label[k] == 0:\n",
    "            tpm = train_data[k]\n",
    "            data_abnormal.append(tpm)    \n",
    "        else:\n",
    "            pass\n",
    "    return np.array(data_normal), np.array(data_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.19901949e-01,  1.06259361e-01, -1.06205232e-03],\n",
       "       [-2.25525051e-01,  1.48062073e-01,  2.51522288e-04],\n",
       "       [ 7.05533288e-02,  2.93040983e-01, -6.80042803e-01],\n",
       "       [ 6.15588017e-02, -1.17207728e-01,  3.75536419e-01],\n",
       "       [-2.26389505e-01,  1.48956813e-01,  1.81373209e-03],\n",
       "       [ 6.19836524e-02, -1.17642581e-01,  3.76462303e-01],\n",
       "       [ 6.29310496e-02, -1.19337086e-01,  3.78983542e-01],\n",
       "       [ 6.21868856e-02, -1.17961876e-01,  3.76976170e-01],\n",
       "       [-2.21952647e-01, -4.99630347e-03, -1.02837924e-01],\n",
       "       [-1.43354833e-01,  5.48967160e-02, -1.22782178e-01],\n",
       "       [-1.65550746e-01, -1.82347372e-03, -1.27152428e-01],\n",
       "       [-2.22004317e-01,  1.15851611e-01,  3.42745334e-04]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data0 = train_data[:3][:2]\n",
    "#train_label0 = train_label[:3]\n",
    "#val_data0 = val_data[:3][:2]\n",
    "#val_label0 = val_label[:400]\n",
    "train_data0 = train_data[:20,:3]*10.0\n",
    "train_label0 = train_label[:20]\n",
    "val_data0 = val_data[:20,:3]*10.0\n",
    "val_label0 = val_label[:20]\n",
    "\n",
    "train_data_normal,train_data_abnormal = distribute_normal_abnormal(train_data0,train_label0)\n",
    "training_input = {'Normal':train_data_normal,'Abnormal':train_data_abnormal}\n",
    "test_data_normal,test_data_abnormal = distribute_normal_abnormal(val_data0,val_label0)\n",
    "test_input = {'Normal':test_data_normal,'Abnormal':test_data_abnormal}\n",
    "feature_dim = 3\n",
    "(training_input['Abnormal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit import IBMQ\n",
    "# IBMQ.load_accounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to the limited entangler_map, ZIZ is skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing success ratio: 0.6\n",
      "preduction of datapoints:\n"
     ]
    }
   ],
   "source": [
    "seed = 1088\n",
    "\n",
    "feature_map = SecondOrderExpansion(feature_dimension=feature_dim, depth=3, entanglement='linear')\n",
    "qsvm = QSVM(feature_map, training_input, test_input)\n",
    "\n",
    "backend = BasicAer.get_backend('qasm_simulator')\n",
    "quantum_instance = QuantumInstance(backend, shots=1024, seed=seed, seed_transpiler=seed)\n",
    "\n",
    "result = qsvm.run(quantum_instance)\n",
    "\n",
    "\"\"\"declarative approach\n",
    "params = {\n",
    "    'problem': {'name': 'classification', 'random_seed': 10598},\n",
    "    'algorithm': {\n",
    "        'name': 'QSVM'\n",
    "    },\n",
    "    'backend': {'provider': 'qiskit.BasicAer', 'name': 'qasm_simulator', 'shots': 1024},\n",
    "    'feature_map': {'name': 'SecondOrderExpansion', 'depth': 2, 'entanglement': 'linear'}\n",
    "}\n",
    "algo_input = ClassificationInput(training_input, test_input, datapoints[0])\n",
    "result = run_algorithm(params, algo_input)\n",
    "\"\"\"\n",
    "\n",
    "print(\"testing success ratio: {}\".format(result['testing_accuracy']))\n",
    "print(\"preduction of datapoints:\")\n",
    "#print(\"ground truth: {}\".format(map_label_to_class_name(datapoints[1], qsvm.label_to_class)))\n",
    "#print(\"prediction:   {}\".format(result['predicted_classes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
